
started work around 8:00, clocked in and continued work on the AI lab project headed by Benjamin Bowman. Work on this project has been relatively quick, except for the model inversion lab. Truth be told, neither of us have deep technical experience with AI, though we have significantly deepened our knowledge on the topic over the past three weeks. 

Yesterday, I located a script [here] that generates a basic script for model inversion using simulated financial information. I spent some time this morning setting it up and playing around with the values to produce output similar to that in the article. However, simply reusing the script would not provide enough content for the lab (it also feels akin to stealing). I spent most of the morning coming up with a plan to modify the script for a more engaging lab, cataloging the resources and steps I'd need to do it, and writing down my plan in today's log (see below).

Instead, today's goal will involve the following: 
1. modify the script to train the model on a predefined dataset - either is a .cvs or .xml format (will involve converting the data from the uploaded script into a readable format with pandas)
==This predefined dataset will include the following training data==
- User's City (1 of 5 locations)
- Age
- Income
- Credit Score
- Listed Assets

The locations will reference fictional cities, which are as follows:
- Peoria
- Morton
- Pekin
- Germantown
- Dunlap

Example:

| City   | Age | Income | Credit Score | Assets Value |
| ------ | --- | ------ | ------------ | ------------ |
| Peoria | 24  | 24,000 | 0            | \[2,000]     |
| Morton | 45  | 45,000 | 600          | \[740,000]   |
etc. 

Preset data correlations will be as follows:
- Peoria - high income, young, mediocre credit scores, low asset values
- Morton - low income, old, low credit scores, low asset values
- Pekin - medium income, varied age, high credit scores, medium asset values
- Germantown - medium income, middle age, medicore credit scores, medium asset values
- Dunlap - really high income, middle-old age, high credit scores, high asset values

- Peoria 120,000 - 150,000, 19-24, 580-669, 10,000-24,000
- Morton - 2,000 - 25,000, 60-90, 0-150, 0 - 12,000
- Pekin - 32,000 - 62,000, 23-70, 670-800, 50,000 - 270,000
- Germantown - 32,000 - 62,000, 32-38, 570-600, 50,000 - 100,000
- Dunlap - 200,000 - 1,000,000, 32-70, 700-800, 250,000 - 850,000

Code as of writing: 

```python
import pandas as pd

import numpy as np

from sklearn.ensemble import RandomForestClassifier

from sklearn.model_selection import train_test_split

from sklearn.preprocessing import OneHotEncoder as ohe

  

np.random.seed(42) #random seed

n_samples = 10 #number of samples to generate

  

def generate_data(city_name, city_code, income_range, age_range, credit_score_range, asset_value_range):

income = np.random.randint(income_range[0], income_range[1], size=n_samples)

age = np.random.randint(age_range[0], age_range[1], size=n_samples)

credit_score = np.random.randint(credit_score_range[0], credit_score_range[1], size=n_samples)

assets_value = np.random.randint(asset_value_range[0], asset_value_range[1], size=n_samples)

  

#approval script goes here

approved = []

for score, inc in zip(credit_score, income):

if score >= 801:

approved.append(True) # 99% approval

elif 751 <= score <= 800:

approved.append(np.random.rand() < 0.95) # 95% approval

elif 700 <= score <= 750:

approved.append(np.random.rand() < 0.87) # 87% approval

elif 600 <= score < 700 and inc >= 80000:

approved.append(True) # 100% approval for this condition

else:

approved.append(False)

  

data = pd.DataFrame({'City':city_name, 'City_Code': city_code, 'Age': age, 'Income': income, 'CreditScore': credit_score, 'Approved': approved})

return data

  

main_frame = generate_data('Peoria', 0, (120000, 150000), (19,24), (580, 669),(10000,24000))

main_frame = main_frame.append(generate_data('Morton', 1, (2000, 25000), (60,90), (0, 150), (0, 12000)), ignore_index=True)

main_frame = main_frame.append(generate_data('Pekin', 2, (32000, 62000), (23, 70), (670, 800), (50000, 270000)), ignore_index=True)

main_frame = main_frame.append(generate_data('Germantown', 3, (32000, 62000), (32, 38), (570, 600), (50000, 100000)), ignore_index=True)

main_frame = main_frame.append(generate_data('Dunlap', 4, (200000, 1000000), (32, 70), (700, 800), (250000, 850000)), ignore_index=True)

  
  

#model creation

X = main_frame[['City_Code', 'Income', 'CreditScore']]

y = main_frame['Approved']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = RandomForestClassifier(n_estimators=100, random_state=42)

model.fit(X_train, y_train)

  

user_input = pd.DataFrame({'City_Code': 1, 'Income': 20000, 'CreditScore': 0}, index=[0])

probas = model.predict_proba(user_input)

  
  

print(probas)
```

Pretty neat!

The last line, print(probas), will output two numbers in an array. The first number represents the chance of NOT getting the loan, the second number represents the chance that you WILL get the loan. 

Because this model is intentionally flawed to consider people's location as part of it's predictions, people from Dunlap and Peoria will have a higher chance of getting a loan compared to people from Morton.

Model output with income of 100000, 800 credit score, and location of Dunlap

\[\[0.05 0.95]]

Same inputs, but now location is Morton

\[\[0.08 0.92]]

Notice how the chance of getting a loan if you're from Morton decreases automatically merely because of your location! This tells us that people who applied for a bank loan at this bank who are from Morton are more likely to be denied. If we know the bank's requirements for denying loans, we can infer what an individual's financial status is, which is a breach of privacy!


2. Building a website for our lab

The next step of this today's project is building a simulated bank website for our lab. 

Users should fill the following: 
- Location (will be mapped to a city code in the backend)
- Income
- Credit score 

Made progress on the webpage before clocking out.